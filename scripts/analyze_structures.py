#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Analyzes generated crystal structures.

This script reads CIF files generated by MatterGen, uses Pymatgen to analyze
their structural properties, and queries the Materials Project API to find
matching known materials and their properties.
"""

import os
import sys
import argparse
import logging
import json
import time
import zipfile
import pandas as pd
import numpy as np
from pathlib import Path
from tqdm import tqdm
import concurrent.futures
import traceback
from io import StringIO # Not strictly needed here but good for string IO if parsing string CIFs

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('analyze_structures')

# Check for required libraries
try:
    from pymatgen.core import Structure
    from pymatgen.analysis.structure_matcher import StructureMatcher, ElementComparator
    from pymatgen.entries.computed_entries import ComputedStructureEntry
    from pymatgen.ext.matproj import MPRester
    logger.info("Core libraries (pymatgen, mp-api) loaded successfully.")
except ImportError as e:
    logger.error(f"Failed to import essential libraries: {e}")
    logger.error("Please ensure pymatgen and mp-api are installed correctly.")
    sys.exit(1)

# Global variable for arguments to be accessible in helper functions if needed
args = None

def parse_arguments():
    """Parses command-line arguments."""
    parser = argparse.ArgumentParser(description='Analyze MatterGen-generated crystal structures.')
    parser.add_argument('--input_dir', type=str, required=True,
                        help='Directory containing the generated CIF files (usually a zip file named generated_crystals_cif.zip).')
    parser.add_argument('--output_dir', type=str, default=None,
                        help='Directory to save analysis results. Defaults to a subdirectory in project_root/data/analyzed/.')
    parser.add_argument('--mp_api_key', type=str, default=None,
                        help='Materials Project API key. Overrides environment variable MP_API_KEY and config file.')
    parser.add_argument('--max_workers', type=int, default=os.cpu_count() or 1,
                        help='Maximum number of parallel workers for processing CIF files.')
    parser.add_argument('--use_structure_matcher', action='store_true',
                        help='Enable rigorous structure matching using pymatgen.analysis.structure_matcher (can be slow).')
    parser.add_argument('--ltol', type=float, default=0.2, help='StructureMatcher length tolerance.')
    parser.add_argument('--stol', type=float, default=0.3, help='StructureMatcher site tolerance.')
    parser.add_argument('--angle_tol', type=float, default=5.0, help='StructureMatcher angle tolerance.')
    parser.add_argument('--config_file', type=str, default=None,
                        help='Path to a JSON config file for analysis parameters (e.g., ../configs/analysis_configs.json).')
    return parser.parse_args()

def load_config(config_file_path):
    """Loads analysis configuration from a JSON file."""
    if config_file_path and Path(config_file_path).exists():
        with open(config_file_path, 'r') as f:
            return json.load(f)
    return {}

def get_effective_config(cmd_args, file_config):
    """Merges command-line arguments and file configurations."""
    config = file_config.get("default", {}) # Start with defaults from config file

    # Override with more specific settings from config file if they exist
    if cmd_args.use_structure_matcher:
        matcher_config = file_config.get("novelty_criteria", {})
        config["structure_matcher_ltol"] = matcher_config.get("structure_matching_ltol", cmd_args.ltol)
        config["structure_matcher_stol"] = matcher_config.get("structure_matching_stol", cmd_args.stol)
        config["structure_matcher_angle_tol"] = matcher_config.get("structure_matching_angle_tol", cmd_args.angle_tol)

    # Command-line arguments take precedence
    config["mp_api_key"] = cmd_args.mp_api_key or os.environ.get('MP_API_KEY') or config.get("mp_api_key")
    config["max_workers"] = cmd_args.max_workers
    config["use_structure_matcher"] = cmd_args.use_structure_matcher or config.get("structure_matcher", False)
    config["e_hull_threshold"] = file_config.get("filtering", {}).get("e_hull_max", 0.1) # Get from filtering section

    if not config["mp_api_key"]:
        logger.warning("MP_API_KEY not found in command line, environment variables, or config file. MP queries will be skipped.")

    return config

def setup_output_directory(input_dir_str, specified_output_dir_str):
    """Sets up the output directory for analysis results."""
    input_path = Path(input_dir_str)
    if specified_output_dir_str:
        output_dir = Path(specified_output_dir_str)
    else:
        project_root = Path(__file__).resolve().parent.parent
        # Use the name of the input directory (e.g., "LiPS_ehull_0.05") for the output subdirectory
        output_dir = project_root / "data" / "analyzed" / input_path.name
    
    output_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"Analysis results will be saved to: {output_dir}")
    return output_dir

def extract_cif_contents_from_zip(cif_zip_path):
    """Extracts CIF file contents from a zip archive into a list of (filename, content_str)."""
    cif_data_list = []
    if not cif_zip_path.exists():
        logger.error(f"CIF zip file not found: {cif_zip_path}")
        return cif_data_list

    try:
        with zipfile.ZipFile(cif_zip_path, 'r') as zf:
            for member_name in zf.namelist():
                if member_name.endswith('.cif'):
                    try:
                        cif_content = zf.read(member_name).decode('utf-8')
                        cif_data_list.append((Path(member_name).name, cif_content))
                    except Exception as e:
                        logger.warning(f"Could not read or decode {member_name} from zip: {e}")
        logger.info(f"Extracted {len(cif_data_list)} CIF files from {cif_zip_path}")
    except zipfile.BadZipFile:
        logger.error(f"Bad zip file: {cif_zip_path}")
    except Exception as e:
        logger.error(f"Error processing zip file {cif_zip_path}: {e}")
    return cif_data_list


def process_single_cif(cif_filename, cif_content_str, mp_rester, effective_config):
    """
    Analyzes a single CIF string, queries MP, and returns a dictionary of properties.
    """
    analysis_result = {
        "cif_file": cif_filename,
        "formula_generated": None,
        "elements_generated": None,
        "chemsys_generated": None,
        "num_sites_generated": None,
        "density_generated": None,
        "volume_generated": None,
        "spacegroup_generated": None, # Added spacegroup
        "mp_matches": [], # List of dicts for each MP match
        "best_mp_id": None,
        "best_mp_formation_energy_per_atom": None,
        "best_mp_e_above_hull": None,
        "is_stable_on_mp": False, # Based on best_mp_e_above_hull
        "is_novel_by_formula": True, # True if no formula match on MP
        "is_novel_by_structure": True, # True if no structure match on MP (if checked)
        "error": None
    }

    try:
        # Parse structure from CIF string
        # Use StringIO to treat the string as a file
        structure_gen = Structure.from_str(cif_content_str, fmt="cif")
        
        analysis_result["formula_generated"] = structure_gen.composition.reduced_formula
        analysis_result["elements_generated"] = sorted(list(el.symbol for el in structure_gen.composition.elements))
        analysis_result["chemsys_generated"] = "-".join(analysis_result["elements_generated"])
        analysis_result["num_sites_generated"] = structure_gen.num_sites
        analysis_result["density_generated"] = structure_gen.density
        analysis_result["volume_generated"] = structure_gen.volume
        
        # Get spacegroup information
        # TODO: Add more detailed Pymatgen analysis here if needed, e.g. symmetry analysis,
        # defect analysis (requires more context), or specific property calculations from structure.
        # Refer to Cif2Atoms_named_packed.ipynb for examples of Pymatgen's capabilities like
        # SpacegroupAnalyzer, SlabGenerator, etc., for future, more in-depth "后续步骤".
        try:
            from pymatgen.symmetry.analyzer import SpacegroupAnalyzer
            spa = SpacegroupAnalyzer(structure_gen)
            analysis_result["spacegroup_generated"] = {
                "symbol": spa.get_space_group_symbol(),
                "number": spa.get_space_group_number(),
                "crystal_system": spa.get_crystal_system()
            }
        except Exception as e_sg:
            logger.warning(f"Could not get spacegroup for {cif_filename}: {e_sg}")
            analysis_result["spacegroup_generated"] = None


        if not mp_rester:
            return analysis_result # Return basic info if no MPRester

        # Query Materials Project by chemical system
        # This is a broad query; refine by formula if too many results
        mp_docs = mp_rester.materials.summary.search(
            chemsys=analysis_result["chemsys_generated"],
            fields=["material_id", "formula_pretty", "formation_energy_per_atom",
                    "energy_above_hull", "structure", "theoretical", "nsites", "nelements"]
        )
        
        if mp_docs:
            analysis_result["is_novel_by_formula"] = True # Assume novel until a formula match is found
            min_e_above_hull_for_formula_match = float('inf')
            
            # Initialize StructureMatcher if enabled
            structure_matcher = None
            if effective_config["use_structure_matcher"]:
                structure_matcher = StructureMatcher(
                    ltol=effective_config["structure_matcher_ltol"],
                    stol=effective_config["structure_matcher_stol"],
                    angle_tol=effective_config["structure_matcher_angle_tol"],
                    primitive_cell=True, scale=True, comparator=ElementComparator()
                )

            for doc in mp_docs:
                mp_match_info = {
                    "mp_id": str(doc.material_id), # Ensure string
                    "formula_mp": doc.formula_pretty,
                    "formation_energy_per_atom_mp": doc.formation_energy_per_atom,
                    "e_above_hull_mp": doc.energy_above_hull,
                    "is_theoretical_mp": doc.theoretical,
                    "structure_match_pymatgen": None
                }

                # Check for formula match (simplistic, based on reduced formula)
                # Pymatgen's Composition objects can be compared directly for equivalence
                if structure_gen.composition.reduced_composition == doc.structure.composition.reduced_composition:
                    analysis_result["is_novel_by_formula"] = False # Found a formula match
                    
                    # Update best MP entry if this one is more stable
                    if doc.energy_above_hull is not None and doc.energy_above_hull < min_e_above_hull_for_formula_match:
                        min_e_above_hull_for_formula_match = doc.energy_above_hull
                        analysis_result["best_mp_id"] = str(doc.material_id)
                        analysis_result["best_mp_formation_energy_per_atom"] = doc.formation_energy_per_atom
                        analysis_result["best_mp_e_above_hull"] = doc.energy_above_hull
                        if doc.energy_above_hull <= effective_config["e_hull_threshold"]: # Use configured threshold
                             analysis_result["is_stable_on_mp"] = True
                        else:
                             analysis_result["is_stable_on_mp"] = False


                    # Perform structure matching if enabled and formula matches
                    if structure_matcher and doc.structure:
                        try:
                            are_match = structure_matcher.fit(structure_gen, doc.structure)
                            mp_match_info["structure_match_pymatgen"] = are_match
                            if are_match:
                                analysis_result["is_novel_by_structure"] = False # Found a structure match
                        except Exception as e_sm:
                            logger.warning(f"StructureMatcher failed for {cif_filename} vs {doc.material_id}: {e_sm}")
                
                analysis_result["mp_matches"].append(mp_match_info)
            
            # If no formula match was found after checking all docs, it remains novel by formula.
            # If structure matching was off, novelty by structure remains true (conservative)
            if not effective_config["use_structure_matcher"]:
                 analysis_result["is_novel_by_structure"] = "NotChecked"


    except Exception as e:
        logger.error(f"Error processing CIF {cif_filename}: {e}")
        logger.debug(traceback.format_exc())
        analysis_result["error"] = str(e)
        
    return analysis_result

def run_parallel_analysis(cif_data_list, mp_rester, effective_config):
    """Processes CIF files in parallel."""
    results_list = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=effective_config["max_workers"]) as executor:
        future_to_cif_name = {
            executor.submit(process_single_cif, cif_name, cif_content, mp_rester, effective_config): cif_name
            for cif_name, cif_content in cif_data_list
        }
        
        for future in tqdm(concurrent.futures.as_completed(future_to_cif_name), total=len(cif_data_list), desc="Analyzing structures"):
            cif_name = future_to_cif_name[future]
            try:
                result = future.result()
                results_list.append(result)
            except Exception as e:
                logger.error(f"Task for {cif_name} generated an exception: {e}")
                results_list.append({"cif_file": cif_name, "error": str(e)}) # Log error for this file
                
    return results_list

def save_analysis_results(results_df, summary_stats, output_dir_path):
    """Saves the analysis results to CSV and summary to JSON."""
    # Save detailed results
    detailed_csv_path = output_dir_path / "analyzed_structures.csv"
    results_df.to_csv(detailed_csv_path, index=False)
    logger.info(f"Detailed analysis results saved to: {detailed_csv_path}")

    # Save summary statistics
    summary_json_path = output_dir_path / "analysis_summary_statistics.json"
    with open(summary_json_path, 'w') as f:
        json.dump(summary_stats, f, indent=2)
    logger.info(f"Summary statistics saved to: {summary_json_path}")

    # Output key summary metrics to log
    logger.info(f"Analysis Summary:")
    logger.info(f"  Total structures processed: {summary_stats['total_structures_processed']}")
    logger.info(f"  Successfully parsed: {summary_stats['successfully_parsed']}")
    logger.info(f"  Errors during parsing/processing: {summary_stats['errors_parsing_processing']}")
    if summary_stats.get('mp_queried_count', 0) > 0 :
        logger.info(f"  Found on MP (by formula): {summary_stats['found_on_mp_formula']}")
        logger.info(f"  Novel (by formula): {summary_stats['novel_by_formula']}")
        if args.use_structure_matcher:
            logger.info(f"  Found on MP (by structure match): {summary_stats['found_on_mp_structure']}")
            logger.info(f"  Novel (by structure match): {summary_stats['novel_by_structure']}")
        logger.info(f"  Stable on MP (E_hull <= {effective_config['e_hull_threshold']} eV/atom): {summary_stats['stable_on_mp_count']}")


def generate_summary_statistics(results_list, e_hull_threshold_for_stability):
    """Generates summary statistics from the list of analysis results."""
    total_processed = len(results_list)
    successfully_parsed = sum(1 for r in results_list if r.get("formula_generated") and not r.get("error"))
    errors_processing = sum(1 for r in results_list if r.get("error"))
    
    found_on_mp_formula = sum(1 for r in results_list if not r.get("is_novel_by_formula", True) and not r.get("error"))
    novel_by_formula = sum(1 for r in results_list if r.get("is_novel_by_formula", False) and not r.get("error"))

    found_on_mp_structure = "N/A"
    novel_by_structure = "N/A"
    if any(r.get("is_novel_by_structure") != "NotChecked" for r in results_list if not r.get("error")): # Check if structure matching was done
        found_on_mp_structure = sum(1 for r in results_list if not r.get("is_novel_by_structure", True) and r.get("is_novel_by_structure") is not "NotChecked" and not r.get("error"))
        novel_by_structure = sum(1 for r in results_list if r.get("is_novel_by_structure", False) and not r.get("error"))


    stable_on_mp_count = sum(1 for r in results_list if r.get("is_stable_on_mp", False) and not r.get("error"))

    # E_above_hull distribution for materials found on MP
    e_above_hull_values = [r.get("best_mp_e_above_hull") for r in results_list if r.get("best_mp_e_above_hull") is not None and not r.get("error")]
    e_hull_distribution = {}
    if e_above_hull_values:
        hist, bin_edges = np.histogram(e_above_hull_values, bins=10)
        e_hull_distribution = {
            "counts": hist.tolist(),
            "bin_edges": bin_edges.tolist(),
            "mean": np.mean(e_above_hull_values),
            "median": np.median(e_above_hull_values),
            "min": np.min(e_above_hull_values),
            "max": np.max(e_above_hull_values),
        }

    summary = {
        "total_structures_processed": total_processed,
        "successfully_parsed": successfully_parsed,
        "errors_parsing_processing": errors_processing,
        "mp_queried_count": sum(1 for r in results_list if "mp_matches" in r and not r.get("error")), # Count entries where MP query was attempted
        "found_on_mp_formula": found_on_mp_formula,
        "novel_by_formula": novel_by_formula,
        "found_on_mp_structure": found_on_mp_structure,
        "novel_by_structure": novel_by_structure,
        "stable_on_mp_count": stable_on_mp_count,
        "e_above_hull_distribution_mp_matches": e_hull_distribution,
    }
    return summary

def main():
    global args, effective_config # Make args and effective_config global for easy access
    args = parse_arguments()
    
    # Load file config if provided
    file_config_data = load_config(args.config_file)
    if not file_config_data and not args.config_file : # If no config file try default path
        default_config_path = Path(__file__).resolve().parent.parent / "configs" / "analysis_configs.json"
        if default_config_path.exists():
            logger.info(f"No config file specified, attempting to load default: {default_config_path}")
            file_config_data = load_config(default_config_path)
        else:
            logger.warning(f"Default config file not found at {default_config_path}. Using command-line args and environment variables only.")

    # Determine effective configuration
    effective_config = get_effective_config(args, file_config_data)

    output_dir = setup_output_directory(args.input_dir, args.output_dir)

    # Path to the zip file containing CIFs
    cif_zip_file = Path(args.input_dir) / "generated_crystals_cif.zip"
    if not cif_zip_file.is_file(): # check if it's a file, not a dir
        cif_zip_file = Path(args.input_dir) # maybe input_dir *is* the zip file
        if not cif_zip_file.is_file() or not cif_zip_file.name.endswith(".zip"):
             logger.error(f"Input directory {args.input_dir} does not contain 'generated_crystals_cif.zip', and is not a zip file itself.")
             sys.exit(1)


    cif_data = extract_cif_contents_from_zip(cif_zip_file)
    if not cif_data:
        logger.error("No CIF files extracted. Exiting.")
        return 1

    mp_rester_instance = None
    if effective_config.get("mp_api_key"):
        try:
            mp_rester_instance = MPRester(api_key=effective_config["mp_api_key"])
            logger.info("Successfully connected to Materials Project API.")
        except Exception as e:
            logger.error(f"Failed to initialize MPRester: {e}. MP queries will be skipped.")
    else:
        logger.warning("No MP_API_KEY configured. MP queries will be skipped.")

    analysis_start_time = time.time()
    all_results = run_parallel_analysis(cif_data, mp_rester_instance, effective_config)
    analysis_duration = time.time() - analysis_start_time
    logger.info(f"Analysis of {len(cif_data)} structures completed in {analysis_duration:.2f} seconds.")

    if not all_results:
        logger.info("No results were generated from the analysis.")
        return 0
        
    results_dataframe = pd.DataFrame(all_results)
    
    # Generate summary statistics
    summary_data = generate_summary_statistics(all_results, effective_config["e_hull_threshold"])
    summary_data["analysis_duration_seconds"] = analysis_duration
    summary_data["max_workers_used"] = effective_config["max_workers"]
    summary_data["input_source_zip"] = str(cif_zip_file.name)


    save_analysis_results(results_dataframe, summary_data, output_dir)
    
    logger.info(f"Analysis complete. All results saved in {output_dir}")
    return 0

if __name__ == "__main__":
    sys.exit(main())